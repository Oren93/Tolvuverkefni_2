---
title: "Property price analasys (Tölvuverkefni 2)"
author: "Óðinn Eldon Ragnarsson (oer2@hi.is) and Oren Raz (orr3@hi.is)"
date: "15.2.2020"
output: html_document
---
Importing libraries needed
```{r packages, warning=FALSE, message=FALSE}
library(tidyverse)
library(readr)
library(dplyr)
library(ggplot2)
library(knitr)
```

## a)
First we read the csv file and create a database to work with within R. We then rename the columns of the database to be more readable names. The data in question was published by "Þjóðskrá Íslands" in October 2016 regarding property prices in 2017.
```{r}
oo <- read.csv(file = 'husnaedi.csv', fileEncoding = "UTF-8", sep =';')
oo = oo %>% rename("curent_value" = "nuvirdi",
                   "type" = "teg_eign",
                   "area" = "matssvaedi",
                   "size" = "ibm2",)
```

We pick a seed based on our birhtdays to use to determine which area we will work with. We will only use properties of the type "Íbúðareign" so other entries are filtered out. Finally we remove the type column as it is no longer needed.

```{r}
set.seed(0601)
hverfi<-sample(c(20,90,100),1)
oo <- oo%>%filter(area==hverfi)
oo <- subset(oo, select = -c(area))
oo <- filter(oo, type =="Íbúðareign")
oo <- subset(oo, select = -c(type))
```

As the seed is fixed the same area will be selected every time, in our case `r hverfi`. 

<<<<<<< HEAD
=======
```{r, echo=FALSE}
rm(hverfi)
```
>>>>>>> 4bf9f55bd3e23adaaef27360dd73a5d9b53920f7

## b)
To get an idea of the data we are working with we plot the price distribution of properties. We also define the mean price for later use.

```{r, warning=FALSE, message=FALSE}
ggplot(oo, aes( x=curent_value)) + 
  geom_histogram()+xlab("Price (thousands - ISK)")+ylab("Frequency - Number of properties")
price_mean = mean(oo$curent_value)
```

The mean price is `r round(mean(oo$curent_value), digits=0)` with a variance of `r var(oo$curent_value)`. 

## C)
here we will demonstrate how the mean converges onto a single value with a larger and larger sample size. This information can be very important to whether a mean really tells you something accurate about a data set or wether the mean is taken before the mean converges, in which case that value is most likeley off from the actual mean. As before we will need a seed to ensure that the plot is the same every time. 

```{r}
set.seed(0601)
someVector <- sapply((1:5000),
  function(x) {mean(sample(oo$curent_value, x,replace = TRUE))})      

qplot(x = 1:5000,
      y = someVector,
      geom="line")+ xlab("Sample size")+ ylab("Mean price") +
      geom_hline(yintercept = price_mean, col="red")
```
```{r, echo=FALSE}
rm(someVector)
```

This is the law of large numbers at work. Note that the database only contains `r NROW(oo)` values so we are reusing values to create the full plot.


## d)
Here we create four vectors with 10000 entries. Each entry contains the average of n random values in the dataframe. We use n = 2, 5, 20, 400.

```{r}
staerd <- c(2,5,20,400)
staerd1 <- replicate(n = 10000, mean(sample(oo$curent_value,
        staerd[1],replace = TRUE)),simplify = TRUE )
staerd2 <- replicate(n = 10000, mean(sample(oo$curent_value,
        staerd[2],replace = TRUE)),simplify = TRUE ) 
staerd3 <- replicate(n = 10000, mean(sample(oo$curent_value,
        staerd[3],replace = TRUE)),simplify = TRUE )
staerd4 <- replicate(n = 10000, mean(sample(oo$curent_value,
        staerd[4],replace = TRUE)),simplify = TRUE )
remove(staerd)
```

## e)
These vectors can be used to illustrate how averages taken in the fashion described above form a normal distribution.

```{r}
num <- c(1:10000)
staerd <- tibble(num,staerd1=staerd1, staerd2 = staerd2,
                 staerd3 = staerd3,staerd4=staerd4)
remove(staerd1,staerd2,staerd3,staerd4)

st <- gather(staerd,key="sample", value=staerd,
            c(staerd1,staerd2,staerd3,staerd4))

#works ggplot
ggplot(data = st, aes(x = staerd)) +
    geom_histogram(bins=50)+geom_vline(xintercept = price_mean, col="red")+ ##facet_wrap(~sample)
  facet_wrap(~sample, nrow = 2, ncol = 2, scales = "fixed",
             shrink = TRUE, labeller = "label_value", as.table = TRUE,
             switch = NULL, drop = TRUE, dir = "h", strip.position = "top")
```


## f)
Here we have the same tables with the scales free so the axes adapt to the data. Note how for larger sample sizes i.e. "staerd3" and "staerd4" the data forms a normal distribution centered around the mean with smaller and smaller variances. 

```{r}
ggplot(data = st, aes(x = staerd)) +
  geom_histogram(bins=50)+geom_vline(xintercept = price_mean, col="red")+
  facet_wrap(~sample, nrow = 2, ncol = 2, scales = "free",
             shrink = TRUE, labeller = "label_value", as.table = TRUE,
             switch = NULL, drop = TRUE, dir = "h", strip.position = "top")
```


## g)
Here is a table showing how accurate the means of the vectors created in part d are compared to the actual mean found in part b. It also shows how the variance decreases as n increases.
```{r, comment=NA}
tolfr <- tibble(item=c("n = 2", "n = 5", "n = 20", "n = 400", "dataframe"),
 mean = c(mean(staerd$staerd1), mean(staerd$staerd2),
 mean(staerd$staerd3), mean(staerd$staerd4), mean(oo$curent_value)),
 variance = c(var(staerd$staerd1), var(staerd$staerd2),
 var(staerd$staerd3), var(staerd$staerd4), var(oo$curent_value)))
knitr::kable(tolfr,
  align = 'ccc', table.attr = "class=\"table\"", 
  format = "html")
```

## h)
Central Limit Theorem:

Let $X_1, X_2, . . .X_n$ be
independent random variables all having the same distribution function with ﬁnite expectation $\mu=E[X_i], i=1,2,...,n$ and ﬁnite strictly positive variance $\sigma_2=Var[X_i], i=1,2,,....,n$ then for all $x\in \mathbb{R}$ it holds that

$$P\left ( \frac{X_{1}+...+X_{n}-n\mu}{\sigma \sqrt{n}}\leq x \right )\rightarrow \Phi (x), n\rightarrow \infty$$

## i)

The graphs of the vectors created in part d are all normally distributed, roughly around the true mean as calculated in part b. This is exactly what the central limit theorem would suggest happens. With larger n the values the peak of the expected value of the normal distributions approach the true mean. With larger n values the variance also decreases as the centrail limit theorem dictates.






```{r results="asis", echo=FALSE}
cat("
<style>
.table {
  padding-top: 20em;
   width: 40%;
   margin: 0 auto;
}
th, td, tr {
        border: 1px solid black;}
</style>
")
```